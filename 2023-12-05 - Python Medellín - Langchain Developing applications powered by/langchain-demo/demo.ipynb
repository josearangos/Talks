{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ce2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0158d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?:\"\n",
    "llm.predict(text)\n",
    "\"\"\"\n",
    "> Rainbow Toes Socks\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI \n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content= text),\n",
    "]\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "print(chat.predict(messages))\n",
    "\"\"\"\n",
    "> Rainbow Toe Co.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me the names of the most typical meals from: {country}\"\n",
    ")\n",
    "meals_prompt = prompt_template.format(country=\"Colombia\")\n",
    "\"\"\"\n",
    "> Tell me the names of the most typical meals from \n",
    "\"\"\"\n",
    "llm.predict(meals_prompt)\n",
    "\"\"\"\n",
    "> 1. Bandeja Paisa, 2. Arepas, 3. Sancocho, 4. Ajiaco, 5. Tamales...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_language=\"English\",\n",
    "                            output_language=\"Spanish\",\n",
    "                           text= \"Langchain is awesome\")\n",
    "\"\"\"\n",
    ">\n",
    "\"\"\"\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "translation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "#Chain\n",
    "translation_chain = translation_prompt | llm\n",
    "\n",
    "#Run chain\n",
    "translation_params = {\"input_language\":\"English\",\n",
    "                      \"output_language\":\"Spanish\",\n",
    "                      \"text\":\"Langchain is awesome \"}\n",
    "translation_chain.invoke(translation_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_chain.invoke(translation_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in translation_chain.stream(translation_params):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88da338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a country, and you should generate 5 food of that country in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "\n",
    "human_template = \"{country}\"\n",
    "\n",
    "meals_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template), \n",
    "    (\"human\", human_template), \n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "meals_chain = meals_prompt | llm | CommaSeparatedListOutputParser()\n",
    "\n",
    "chain.invoke({\"country\":\"Colombia\"})\n",
    "\n",
    "# >['Arepas', 'Bandeja Paisa', 'Empanadas', 'Ajiaco', 'Lechona']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meals_chain = meals_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "meals_chain.invoke({\"country\":\"colombia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in meals_chain.stream({\"country\": \"Colombia\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da031de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meals_chain.batch([{\"country\" :\"Colombia\"},\n",
    "            {\"country\" :\"Argentina\"},\n",
    "            {\"country\" :\"Brasil\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec36c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for s in meals_chain.astream({\"country\": \"Colombia\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b055445",
   "metadata": {},
   "outputs": [],
   "source": [
    "await meals_chain.ainvoke({\"country\":\"Argentina\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeae374",
   "metadata": {},
   "outputs": [],
   "source": [
    "await meals_chain.abatch([{\"country\" :\"Colombia\"},\n",
    "            {\"country\" :\"Argentina\"},\n",
    "            {\"country\" :\"Brasil\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#CHAIN\n",
    "meals_chain = meals_prompt | llm\n",
    "\n",
    "#Sync\n",
    "--------------------------------------------------------------------\n",
    "# Invoke\n",
    "--------------------------------------------------------------------\n",
    "meals_chain.invoke({\"country\":\"colombia\"})\n",
    "--------------------------------------------------------------------\n",
    "# Stream\n",
    "for s in meals_chain.stream({\"country\": \"Colombia\"}):\n",
    "    print(s.content, end=\"\", flush=True)\n",
    "--------------------------------------------------------------------\n",
    "# Batch\n",
    "meals_chain.batch([{\"country\" :\"Colombia\"},\n",
    "            {\"country\" :\"Argentina\"},\n",
    "            {\"country\" :\"Brasil\"}])\n",
    "--------------------------------------------------------------------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699dabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "await meals_chain.ainvoke({\"country\":\"colombia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995adbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for s in meals_chain.astream({\"country\": \"Colombia\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "await meals_chain.abatch([{\"country\" :\"Colombia\"},\n",
    "            {\"country\" :\"Argentina\"},\n",
    "            {\"country\" :\"Brasil\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_toolkits import GmailToolkit\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm=ChatOpenAI(temperature=0,model_name=\"gpt-4\")\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///langchain-demo/resources/users.db\")\n",
    "db_toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0))\n",
    "\n",
    "\n",
    "tools = db_toolkit.get_tools()\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    verbose=False,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")\n",
    "\n",
    "class AgentInputs(BaseModel):\n",
    "    input: str\n",
    "\n",
    "agent_executor = agent.with_types(input_type=AgentInputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b531362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_lanchain",
   "language": "python",
   "name": "llms_lanchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
